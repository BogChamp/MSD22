{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZKz9kkucX4r",
        "outputId": "e6b8f787-de91-4ae4-ead7-a04210fac077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TSCP2' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cruiseresearchgroup/TSCP2.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFCs8SapLtVK",
        "outputId": "b012b9b8-f6ef-4963-eb01-256f21d0f345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.8/dist-packages (1.8.5.post0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2022.11.0)\n",
            "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.21.6)\n",
            "Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2.5.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (21.3)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (0.11.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.0+cu116)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch-lightning) (3.19.6)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch\n",
        "\n",
        "from math import floor\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tscp_new as tscp\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score"
      ],
      "metadata": {
        "id": "4DXh_ZVjJ4H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_usc_ds(path, window, mode='train'):\n",
        "\n",
        "    X, lbl = extract_windows(path, window, mode)\n",
        "\n",
        "    if mode == \"all\":\n",
        "        return X, lbl\n",
        "    train_size = int(floor(0.8 * X.shape[0]))\n",
        "    if mode == \"train\":\n",
        "        trainx = X[0:train_size]\n",
        "        trainlbl = lbl[0:train_size]\n",
        "        idx = np.arange(trainx.shape[0])\n",
        "        np.random.shuffle(idx)\n",
        "        trainx = trainx[idx,]\n",
        "        trainlbl = trainlbl[idx]\n",
        "        print('train samples : ', train_size)\n",
        "        return trainx, trainlbl\n",
        "\n",
        "    else:\n",
        "        testx = X[train_size:]\n",
        "        testlbl = lbl[train_size:]\n",
        "        print('test shape {} and number of change points {} '.format(testx.shape, len(np.where(testlbl > 0)[0])))\n",
        "\n",
        "        return testx, testlbl\n",
        "\n",
        "\n",
        "def extract_windows(path, window_size, mode=\"train\"):\n",
        "    #files = os.scandir(path)\n",
        "    windows = []\n",
        "    lbl = []\n",
        "    dataset = sio.loadmat(path+\"usc.mat\")\n",
        "\n",
        "    ts = np.array(dataset['Y'])\n",
        "    ts = ts[:,0]\n",
        "    cp = np.array(dataset['L'])\n",
        "    cp = cp[:,0]\n",
        "\n",
        "    #cp = pd.read_csv(path+\"usc_label.csv\")\n",
        "    num_cp = 0\n",
        "    #ts = np.sqrt(np.power(x[:, 0], 2) + np.power(x[:, 1], 2) + np.power(x[:, 2], 2))\n",
        "    for i in range(0, ts.shape[0] - window_size, 5):\n",
        "        windows.append(np.array(ts[i:i + window_size]))\n",
        "        # print(\"TS\",ts[i:i+window_size])\n",
        "        is_cp = np.where(cp[i:i + window_size] == 1)[0]\n",
        "        if is_cp.size == 0:\n",
        "            is_cp = [0]\n",
        "        else:\n",
        "            num_cp += 1\n",
        "        lbl.append(is_cp[0])\n",
        "\n",
        "        # print(is_cp)\n",
        "\n",
        "\n",
        "    print(\"number of samples : {} /  number of samples with change point : {}\".format(len(windows), num_cp))\n",
        "    windows = np.array(windows)\n",
        "\n",
        "    return windows, np.array(lbl)\n",
        "\n",
        "def load_dataset(path, ds_name, win, bs, mode=\"train\"):\n",
        "    if ds_name == 'HASC':\n",
        "        trainx, trainlbl = load_hasc_ds(path, window = 2 * win, mode=mode)\n",
        "    elif ds_name == \"USC\":\n",
        "        trainx, trainlbl = load_usc_ds(path, window=2 * win, mode=mode)\n",
        "    else:\n",
        "        raise ValueError(\"Undefined Dataset.\")\n",
        "\n",
        "    trainlbl = trainlbl.reshape((trainlbl.shape[0], 1))\n",
        "    print(trainx.shape, trainlbl.shape)\n",
        "    dataset = np.concatenate((trainlbl, trainx), 1)\n",
        "\n",
        "    print(\"dataset shape : \", dataset.shape)\n",
        "    if mode == \"test\":\n",
        "        return dataset\n",
        "    # Create TensorFlow dataset\n",
        "\n",
        "    train_ds = TensorDataset(torch.from_numpy(dataset))\n",
        "    #train_ds = DataLoader(train_ds, bs, num_workers=2)\n",
        "    return train_ds"
      ],
      "metadata": {
        "id": "7Tlj4WxAKuBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_CPs(sim, gt, name, train_name, metric='cosine', threshold=0.5):\n",
        "    #if metric == \"cosine\":\n",
        "    #    sim = _cosine_simililarity_dim1(h, f)\n",
        "\n",
        "    est_cp = np.zeros(sim.shape[0])\n",
        "    est_cp[np.where(sim < threshold)[0]] = 1\n",
        "    tn, fp, fn, tp = confusion_matrix(gt, est_cp).ravel()\n",
        "    f1 = f1_score(gt, est_cp)\n",
        "\n",
        "    ## gt==1\n",
        "    gt_id = np.where(gt == 1)[0]\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    for i in gt_id:\n",
        "        plt.axvline(x=i, ymin=0, ymax=1, color='k')\n",
        "    plt.subplot(2, 1, 2)\n",
        "    for i in np.where(est_cp == 1)[0]:\n",
        "        plt.axvline(x=i, ymin=0, ymax=1, color='r')\n",
        "    plt.savefig(name+\".png\")\n",
        "    plt.savefig(name + \".pdf\")\n",
        "    \"\"\"\n",
        "    print(\"tn {}, fp {}, fn {}, tp {} ----- f1-score {}\".format(tn, fp, fn, tp, f1))\n",
        "\n",
        "    ## continuous series\n",
        "    i = 1\n",
        "    pos, seq_tp, seq_fn, seq_fp = 0, 0, 0, 0\n",
        "\n",
        "    while i < gt.shape[0]:\n",
        "        if gt[i] == 1:\n",
        "            pos += 1\n",
        "            j = i\n",
        "            while gt[i] == 1:\n",
        "                i += 1\n",
        "\n",
        "            if np.sum(est_cp[j:i]) > 0:\n",
        "                seq_tp += 1\n",
        "                est_cp[j:i] = 0\n",
        "            else:\n",
        "                seq_fn += 1\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    seq_fp = np.where(np.diff(est_cp) == 1)[0].shape[0]\n",
        "    seq_f1 = (2 * seq_tp) / (2 * seq_tp + seq_fn + seq_fp)\n",
        "\n",
        "    print(\"SEQ : Pos {}, fp {}, fn {}, tp {} ----- f1-score {}\".format(pos, seq_fp, seq_fn, seq_tp, seq_f1))\n",
        "    result = \"tn, {}, fp, {}, fn, {}, tp, {}, f1-score, {}, Pos, {}, seqfp, {}, seqfn, {}, seqtp, {}, seqf1, {}\\n\".format(tn, fp, fn, tp, f1, pos, seq_fp, seq_fn, seq_tp, seq_f1)\n",
        "    return result"
      ],
      "metadata": {
        "id": "UBIkGMvClX1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DS_NAME = 'USC'\n",
        "DATA_PATH = './TSCP2/data/'\n",
        "OUTPUT_PATH = os.path.join('./output/', DS_NAME)\n",
        "MODEL_PATH = os.path.join('./output/', \"model\")\n",
        "LOSS = 'nce'\n",
        "SIM = 'cosine'\n",
        "GPU = 0\n",
        "\n",
        "WIN = 100\n",
        "CODE_SIZE = 10\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "LR = 1e-4\n",
        "TEMP = 0.5\n",
        "TAU = 0.1\n",
        "BETA = 1\n",
        "EVALFREQ = 25\n",
        "decay_steps = 1000\n",
        "\n",
        "\n",
        "train_name = \"CP2_model_\" + DS_NAME + \"_T\" + str(TEMP) + \"_WIN\" + str(WIN) + \\\n",
        "             \"_BS\" + str(BATCH_SIZE) + \"_CS\" + str(CODE_SIZE) + \"_lr\" + str(LR) + \\\n",
        "             \"_LOSS\" + LOSS +  \"_SIM\" + SIM + \"_TAU\" + str(TAU) + \"_BETA\" + str(BETA)\n",
        "print(\"------------------------------------>>> \" + train_name)\n",
        "\n",
        "# -------------------------------\n",
        "# 1 PREPARE DATASET\n",
        "# -------------------------------\n",
        "train_ds = load_dataset(DATA_PATH, DS_NAME, WIN, BATCH_SIZE, mode = \"train\")\n",
        "test_ds = load_dataset(DATA_PATH, DS_NAME, WIN, BATCH_SIZE, mode = \"test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRB-0W_1JJpE",
        "outputId": "e15c6119-8508-4009-afd4-91051be31bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------>>> CP2_model_USC_T0.5_WIN100_BS32_CS10_lr0.0001_LOSSnce_SIMcosine_TAU0.1_BETA1\n",
            "number of samples : 18687 /  number of samples with change point : 1400\n",
            "train samples :  14949\n",
            "(14949, 200) (14949, 1)\n",
            "dataset shape :  (14949, 201)\n",
            "number of samples : 18687 /  number of samples with change point : 1400\n",
            "test shape (3738, 200) and number of change points 274 \n",
            "(3738, 200) (3738, 1)\n",
            "dataset shape :  (3738, 201)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prep_model = tscp.Encoder(code_size = CODE_SIZE, seq_len = WIN)\n",
        "\n",
        "similarity = tscp._cosine_simililarity_dim2\n",
        "\n",
        "tscp_model = tscp.TSCP_model(prep_model, train_ds, test_ds, batch_size=BATCH_SIZE, temperature=TEMP, lr=LR, decay_steps=decay_steps, window_1=WIN)\n",
        "optimizer = tscp_model.configure_optimizers()\n",
        "lr = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=decay_steps)\n"
      ],
      "metadata": {
        "id": "bSTDxTIoJJlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = tscp_model.train_dataloader()\n",
        "val_loader = tscp_model.val_dataloader()\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "epoch_wise_sim = []\n",
        "epoch_wise_neg = []\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "    \n",
        "    iteration = 0\n",
        "    train_losses_iters = []\n",
        "    step_wise_sim = []\n",
        "    step_wise_neg = []\n",
        "    \n",
        "    for index, batch in enumerate(train_loader):\n",
        "            \n",
        "          loss, sim, neg = tscp_model.training_step(batch, index)\n",
        "          train_losses_iters.append(float(loss))\n",
        "          step_wise_sim.append(float(sim))\n",
        "          step_wise_neg.append(float(neg))\n",
        "          if not iteration % 400:\n",
        "            print(\"train_losses_iters\", train_losses_iters[-1])\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          lr.step()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          iteration += 1\n",
        "            \n",
        "          #print(\"iteration\", iteration)\n",
        "        \n",
        "          if not iteration % 400:\n",
        "            tscp_model.eval()\n",
        "            vall = []\n",
        "            with torch.no_grad():\n",
        "              for c, b in enumerate(val_loader):\n",
        "                val_loss, _, _ = tscp_model.validation_step(b, c)\n",
        "                vall.append(float(val_loss.detach()))\n",
        "                if c>10:\n",
        "                  break\n",
        "              print(\"val_loss\", np.mean(vall))\n",
        "              val_losses.append(np.mean(vall))\n",
        "              \n",
        "            \n",
        "            tscp_model.train()\n",
        "    print(\"epoch_train_loss\", np.mean(train_losses_iters))  \n",
        "    train_losses.append(np.mean(train_losses_iters))\n",
        "    print(\"epoch_val_loss\", np.mean(val_losses))\n",
        "    epoch_wise_sim.append(np.mean(step_wise_sim))\n",
        "    epoch_wise_neg.append(np.mean(step_wise_neg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sygpKdzGJJgX",
        "outputId": "d3bae669-fe6d-472b-db67-f26d17763c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
            "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_losses_iters 0.3131650984287262\n",
            "val_loss 0.3027332586546739\n",
            "train_losses_iters 0.033841852098703384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 1/30 [01:53<55:04, 113.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_train_loss 0.06819479631530678\n",
            "epoch_val_loss 0.3027332586546739\n",
            "train_losses_iters 0.057341329753398895\n",
            "val_loss 0.3027282655239105\n",
            "train_losses_iters 0.03157064691185951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [03:48<53:22, 114.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_train_loss 0.03598870670932353\n",
            "epoch_val_loss 0.30273076208929217\n",
            "train_losses_iters 0.03559800982475281\n",
            "val_loss 0.30271531144777936\n",
            "train_losses_iters 0.032975003123283386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [05:44<51:48, 115.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_train_loss 0.03377771104534722\n",
            "epoch_val_loss 0.3027256118754546\n",
            "train_losses_iters 0.03375104069709778\n",
            "val_loss 0.3043800046046575\n",
            "train_losses_iters 0.037485864013433456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [07:41<50:15, 115.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch_train_loss 0.03583169599167175\n",
            "epoch_val_loss 0.3031392100577553\n",
            "train_losses_iters 0.03560640662908554\n",
            "val_loss 0.30416984111070633\n",
            "train_losses_iters 0.038103386759757996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "            'model_state_dict': tscp_model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, './tscp1001032_opt.pt')"
      ],
      "metadata": {
        "id": "0RikDZy3HjyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpt = torch.load('tscp7588_opt.pt')\n",
        "tscp_model.load_state_dict(cpt['model_state_dict'])\n",
        "optimizer.load_state_dict(cpt['optimizer_state_dict'])"
      ],
      "metadata": {
        "id": "7axUm5QvH4BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, lbl_test = test_ds[:,1:], test_ds[:,0]\n",
        "\n",
        "num = x_test.shape[0]\n",
        "lbl_test = np.array(lbl_test).reshape((lbl_test.shape[0], 1))\n",
        "history = prep_model(torch.from_numpy(x_test[:, 0:WIN].reshape((num, 1, WIN))).float())\n",
        "future = prep_model(torch.from_numpy(x_test[:, WIN:].reshape((num, 1, WIN))).float())\n",
        "pred_out = np.concatenate((lbl_test, history.detach().numpy(), future.detach().numpy()), 1)\n",
        "rep_sim = tscp._cosine_simililarity_dim1(history, future)\n",
        "\n",
        "#np.savetxt(os.path.join(OUTPUT_PATH, \"pred_sim\", train_name + \"_pred_sim.csv\"), np.concatenate((lbl_test, np.array(rep_sim).reshape((rep_sim.shape[0],1))),1), delimiter=',',\n",
        "#                   header=\"lbl,\"+LOSS, comments=\"\")\n",
        "#print(\"Saved test similarity result!\")\n",
        "\n",
        "#history = history.detach().numpy()\n",
        "#future = future.detach().numpy()\n",
        "print('Average similarity for test set : Reps : {}'.format(np.mean(rep_sim.detach().numpy())))\n",
        "gt = np.zeros(lbl_test.shape[0])\n",
        "gt[np.where((lbl_test > int(2 * WIN * 0.15)) & (lbl_test < int(2 * WIN * 0.85)))[0]] = 1\n",
        "# threshold_segmentation(h_pred,f_pred, gt, train_name, os.path.join(OUT_PATH,\"Evaluation.txt\"), threshold = np.mean(rep_sim) - np.std(rep_sim))\n",
        "result = estimate_CPs(rep_sim.detach().numpy(), gt, os.path.join(OUTPUT_PATH, train_name),\n",
        "                    os.path.join(OUTPUT_PATH, \"Evaluation.txt\"),\n",
        "                    metric='cosine', threshold=0.5)"
      ],
      "metadata": {
        "id": "q3T7FqOhHnDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = estimate_CPs(rep_sim.detach().numpy(), gt, os.path.join(OUTPUT_PATH, train_name),\n",
        "                    os.path.join(OUTPUT_PATH, \"Evaluation.txt\"),\n",
        "                    metric='cosine', threshold=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQUBGXjWMJVL",
        "outputId": "6d38ec72-dff0-415a-a0e4-a273abe0f567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tn 3577, fp 17, fn 112, tp 34 ----- f1-score 0.3451776649746193\n",
            "SEQ : Pos 7, fp 2, fn 5, tp 2 ----- f1-score 0.36363636363636365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAWOI9PbJJMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XrRQA4kkVjI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}